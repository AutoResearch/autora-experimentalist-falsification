{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Basic Usage\n",
    "The falsification pooler identifies experiment conditions under which the loss $\\hat{\\mathcal{L}}(M,X,Y,\\vec{x})$ of the best candidate model is predicted to be the highest. This loss is approximated with a multi-layer perceptron, which is trained to predict the loss of a candidate model, $M$, given experiment conditions $X$  and dependent measures $Y$ that have already been probed.\n",
    "\n",
    "We begin with importing the relevant packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from autora.variable import DV, IV, ValueType, VariableCollection\n",
    "from autora.experimentalist.pooler.falsification import falsification_pooler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Example 1: Sampling fom a Sinus Function\n",
    "\n",
    "In this example, we will consider a dataset resembling the sine function. We will then fit a linear model to the data and use the falsification pooler to identify experiment conditions under which the model is predicted to perform the worst.\n",
    "\n",
    "First, we define the independent variable $x$ and the dependent variable $y$. We consider a domain of $x \\in [0, 2\\pi]$, and sample 100 data points from this domain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "x = np.linspace(0, 2 * np.pi, 100)\n",
    "y = np.sin(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "We define the candidate experimental conditons $X'$ from which we seek to sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "X_prime = np.array([1, 2, 3, 4, 5, 6, 7, 8, 9, 10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Next, we need to specify how many samples we would like to collect. In this case, we pick $n=2$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "n = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Finally, we can call the novelty sampler. Note that $X'$ is the first argument to the sampler, followed by the \"reference\" conditions $X$, and the number of samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'novelty_sampler' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[5], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m X_sampled \u001B[38;5;241m=\u001B[39m \u001B[43mnovelty_sampler\u001B[49m(condition_pool \u001B[38;5;241m=\u001B[39m X_prime, reference_conditions \u001B[38;5;241m=\u001B[39m X, num_samples \u001B[38;5;241m=\u001B[39m n, metric \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124meuclidean\u001B[39m\u001B[38;5;124m\"\u001B[39m, integration \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124msum\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m      2\u001B[0m \u001B[38;5;28mprint\u001B[39m(X_sampled)\n",
      "\u001B[0;31mNameError\u001B[0m: name 'novelty_sampler' is not defined"
     ]
    }
   ],
   "source": [
    "X_sampled = novelty_sampler(condition_pool = X_prime, reference_conditions = X, num_samples = n, metric = \"euclidean\", integration = \"sum\")\n",
    "print(X_sampled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The novelty sampler also works for experiments with multiple indendent variables. In the following example, we define $X$ as a single experimental condition composed of three independent factors. We choose from a pool $X'$ composed of four experimental conditons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "X = np.array([[1, 1, 1]])\n",
    "X_prime = np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9], [10, 11, 12]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Next, we sample a single experimental condition from the pool $X'$ which yields the greatest summed Euclidean distance to the existing condition in $X$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "X_sampled = novelty_sampler(condition_pool = X_prime, reference_conditions = X, num_samples = 1, metric = \"euclidean\", integration = \"sum\")\n",
    "print(X_sampled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "We can also obtain \"novelty\" scores for the sampled experiment conditions using ``novelty_score_sampler''. The scores are z-scored with respect to all conditions from the pool. In the following example, we sample 2 conditions and return their novelty scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "X_sampled, scores = novelty_score_sampler(condition_pool = X_prime, reference_conditions = X, num_samples = 2, metric = \"euclidean\", integration = \"sum\")\n",
    "print(X_sampled)\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The novelty scores align with the sampled experiment conditions (in descending order of the novelty score)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}